{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99263fa-be94-456e-a407-3e022b84df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "from sort.sort import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2666df2-a846-4c98-a06e-ea88138ebfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yolo_detector = YOLO('yolov8s.pt')\n",
    "\n",
    "checkpoint = \"./sam2_model/sam2.1_hiera_small.pt\"\n",
    "model_cfg = \"C:/Users/Gerardo/Documents/SAM2/sam2_model/sam2.1_hiera_s.yaml\"\n",
    "sam_segment = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))\n",
    "\n",
    "mot_tracker = Sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4497dfe-4b56-491c-a151-9da99e1d016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 1 bus, 2 trucks, 59.8ms\n",
      "Speed: 4.3ms preprocess, 59.8ms inference, 81.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "video = cv2.VideoCapture('./video/cars.mp4')\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#print(int(video.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Specify the codec\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "width = 20+2*int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter('./video/cars_processed.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "vehicle_ids = [2, 3, 5, 7]\n",
    "\n",
    "colors = {}\n",
    "vehicle_type = {}\n",
    "frame_num = -1\n",
    "ret = True\n",
    "alpha = 0.5\n",
    "\n",
    "\n",
    "while ret:\n",
    "    frame_num += 1\n",
    "    print(frame_num)\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    vehicles = yolo_detector(frame_rgb,device=0)[0]\n",
    "\n",
    "    vehicle_boxes = []\n",
    "    for vehicle in vehicles.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = vehicle\n",
    "        x1 = int(x1)\n",
    "        y1 = int(y1)\n",
    "        x2 = int(x2)\n",
    "        y2 = int(y2)\n",
    "        class_id = int(class_id)\n",
    "        \n",
    "        if class_id in vehicle_ids:\n",
    "            vehicle_boxes.append([x1, y1, x2, y2, score])\n",
    "        \n",
    "    \n",
    "    track_ids = mot_tracker.update(np.asarray(vehicle_boxes))\n",
    "\n",
    "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "        sam_segment.set_image(frame_rgb)\n",
    "        \n",
    "        for track_id in track_ids:\n",
    "            x1, y1, x2, y2, id_num = track_id\n",
    "            x1 = int(x1)\n",
    "            y1 = int(y1)\n",
    "            x2 = int(x2)\n",
    "            y2 = int(y2)\n",
    "            id_num = int(id_num)\n",
    "            \n",
    "            colored_mask = np.zeros_like(frame_rgb)\n",
    "\n",
    "            if id_num not in colors.keys():\n",
    "                colors[id_num] = {\"r\" : random.randint(0, 255), \"g\" : random.randint(0, 255), \"b\" : random.randint(0, 255)}\n",
    "                \n",
    "                for vehicle in vehicles.boxes.data.tolist():\n",
    "                    cx1, cy1, cx2, cy2, cscore, cid = vehicle\n",
    "                    cx1 = int(cx1)\n",
    "                    cy1 = int(cy1)\n",
    "                    cx2 = int(cx2)\n",
    "                    cy2 = int(cy2)\n",
    "                    cid = int(cid)\n",
    "                    \n",
    "                    if cx1 == x1 and cy1 == y1 and cx2 == x2 and cy2 == y2 and id_num not in vehicle_type: \n",
    "                        if cid == 2:\n",
    "                            vehicle_type[id_num] = \"car\"\n",
    "                        if cid == 3:\n",
    "                            vehicle_type[id_num] = \"bike\"\n",
    "                        if cid == 5:\n",
    "                            vehicle_type[id_num] = \"bus\"\n",
    "                        if cid == 7:\n",
    "                            vehicle_type[id_num] = \"truck\"\n",
    "            \n",
    "            mask_color = [colors[id_num][\"r\"], colors[id_num][\"g\"], colors[id_num][\"b\"]]\n",
    "            \n",
    "            input_box = np.array([x1, y1, x2, y2])\n",
    "            mask, _, _ = sam_segment.predict(box=input_box, multimask_output=False)\n",
    "\n",
    "            xmin = 10000\n",
    "            ymin = 10000\n",
    "            xmax = -1\n",
    "            ymax = -1\n",
    "\n",
    "            for i in range(mask.shape[1]):\n",
    "                for j in range(mask.shape[2]):\n",
    "                    if(int(mask[0,i,j]) == 1):\n",
    "                        colored_mask[i,j] = mask_color\n",
    "                        if i < ymin:\n",
    "                            ymin = i\n",
    "                        if j < xmin:\n",
    "                            xmin = j\n",
    "                        if i > ymax:\n",
    "                            ymax = i\n",
    "                        if j > xmax:\n",
    "                            xmax = j\n",
    "           \n",
    "            \n",
    "            frame_rgb = cv2.addWeighted(frame_rgb, 1, colored_mask, alpha, 0)\n",
    "\n",
    "            if (ymin - 25) >= 0 and (xmin + 110) < width:\n",
    "                cv2.rectangle(frame_rgb, (xmin, ymin - 25), (xmin + 110, ymin), (255,255,255), thickness = -1)\n",
    "                cv2.putText(frame_rgb, f\"{id_num} - {vehicle_type[id_num]}\", (xmin,ymin-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0),2)\n",
    "            \n",
    "        overlay_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        band = np.full((height, 20, 3), 128, dtype = np.uint8)\n",
    "\n",
    "        final_image = np.hstack((frame,band,overlay_bgr))\n",
    "\n",
    "        #cv2.imwrite(\"conc.jpg\", final_image)\n",
    "        #cv2.imwrite(\"processed_frame.jpg\", overlay_bgr)\n",
    "        out.write(final_image)\n",
    "        \n",
    "out.release()\n",
    "video.release()\n",
    "\n",
    "print(\"Complete\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAM22",
   "language": "python",
   "name": "sam22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
